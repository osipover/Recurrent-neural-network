{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# GRU (Gated Recurrent Unit)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "321049e3f66e6033"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "from sklearn.metrics import root_mean_squared_error, r2_score"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-22T14:53:21.280683100Z",
     "start_time": "2024-05-22T14:53:21.220406800Z"
    }
   },
   "id": "68ee81e5c908b0ed",
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def sigmoid_derivative(x):\n",
    "    return sigmoid(x) * (1 - sigmoid(x))\n",
    "\n",
    "def tanh(x):\n",
    "    return np.tanh(x)\n",
    "\n",
    "def tanh_derivative(x):\n",
    "    return 1 - np.tanh(x)**2"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-22T14:53:21.317193800Z",
     "start_time": "2024-05-22T14:53:21.289671800Z"
    }
   },
   "id": "2aca140e0c6e00b8",
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "class GRU:\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        \n",
    "        self.weights_z = self.__init_weights((input_size + hidden_size, hidden_size))\n",
    "        self.biases_z = np.zeros((hidden_size,))\n",
    "        \n",
    "        self.weights_r = self.__init_weights((input_size + hidden_size, hidden_size))\n",
    "        self.biases_r = np.zeros((hidden_size,))\n",
    "        \n",
    "        self.weights_h = self.__init_weights((input_size + hidden_size, hidden_size))\n",
    "        self.biases_h = np.zeros((hidden_size,))\n",
    "        \n",
    "        self.weights_output = self.__init_weights((hidden_size, output_size))\n",
    "        self.biases_output = np.zeros((output_size,))\n",
    "        \n",
    "        self.h_prev = np.zeros((hidden_size,))\n",
    "\n",
    "    def __forward_propagation(self, x):\n",
    "        x_and_h_prev = np.hstack([x, self.h_prev])\n",
    "        \n",
    "        zt = sigmoid(np.dot(x_and_h_prev, self.weights_z) + self.biases_z)\n",
    "        rt = sigmoid(np.dot(x_and_h_prev, self.weights_r) + self.biases_r)\n",
    "        self.h_prev = zt * self.h_prev + (1 - zt) * tanh(np.dot(np.hstack([x, rt * self.h_prev]), self.weights_h) + self.biases_h)\n",
    "        \n",
    "        y = np.dot(self.h_prev, self.weights_output) + self.biases_output        \n",
    "        return y\n",
    "\n",
    "    def __backward_propagation(self, x, dy, learning_rate):\n",
    "        x_and_h_prev = np.hstack([x, self.h_prev])\n",
    "        \n",
    "        zt = sigmoid(np.dot(x_and_h_prev, self.weights_z) + self.biases_z)\n",
    "        rt = sigmoid(np.dot(x_and_h_prev, self.weights_r) + self.biases_r)\n",
    "        combined_r = np.hstack([x, rt * self.h_prev])\n",
    "        \n",
    "        dh = np.dot(dy, self.weights_output.T)\n",
    "        dht_candidate = dh * (1 - zt) * (1 - tanh(np.dot(combined_r, self.weights_h) + self.biases_h)**2)\n",
    "        \n",
    "        dwh = np.outer(combined_r, dht_candidate)\n",
    "        dbh = dht_candidate\n",
    "        \n",
    "        drt = np.dot(dht_candidate, self.weights_h.T[:, :self.hidden_size]) * rt * (1 - rt) * self.h_prev\n",
    "        dwr = np.outer(x_and_h_prev, drt)\n",
    "        dbr = drt\n",
    "        \n",
    "        dzt = dh * (self.h_prev - tanh(np.dot(combined_r, self.weights_h) + self.biases_h)) * zt * (1 - zt)\n",
    "        dwz = np.outer(x_and_h_prev, dzt)\n",
    "        dbz = dzt\n",
    "        \n",
    "        self.weights_h -= learning_rate * dwh\n",
    "        self.weights_r -= learning_rate * dwr\n",
    "        self.weights_z -= learning_rate * dwz\n",
    "        self.weights_output -= learning_rate * np.outer(self.h_prev, dy)\n",
    "\n",
    "        self.biases_h -= learning_rate * dbh\n",
    "        self.biases_r -= learning_rate * dbr\n",
    "        self.biases_z -= learning_rate * dbz\n",
    "        self.biases_output -= learning_rate * dy\n",
    "\n",
    "        self.h_prev = zt * self.h_prev + (1 - zt) * tanh(np.dot(combined_r, self.weights_h) + self.biases_h)\n",
    "        \n",
    "    def fit(self, x_train, y_train, epochs=100, learning_rate=0.001, batch_size=16):\n",
    "        for epoch in range(epochs):\n",
    "            perm = np.random.permutation(len(x_train))\n",
    "            for i in range(0, len(x_train), batch_size):\n",
    "                batch_indices = perm[i:i + batch_size]\n",
    "                batch_x = x_train[batch_indices]\n",
    "                batch_y = y_train[batch_indices]\n",
    "                outputs = []\n",
    "                for x in batch_x:\n",
    "                    out = self.__forward_propagation(x)\n",
    "                    outputs.append(out)\n",
    "                gradients = 2 * (outputs - batch_y) / batch_size\n",
    "                for j in range(len(gradients) - 1, 0, -1):\n",
    "                    self.__backward_propagation(batch_x[j], gradients[j], learning_rate)\n",
    "                    \n",
    "    def predict(self, x):\n",
    "        return self.__forward_propagation(x)\n",
    "        \n",
    "    def __init_weights(self, size):\n",
    "        return np.random.uniform(-1, 1, size)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-22T14:53:21.376556200Z",
     "start_time": "2024-05-22T14:53:21.341199500Z"
    }
   },
   "id": "643c504dfa1d4107",
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "df = pd.read_csv('resources/Clear_steel_industry_data.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-22T14:53:21.442303200Z",
     "start_time": "2024-05-22T14:53:21.355552Z"
    }
   },
   "id": "4b1b8ee533ecbf38",
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "x = df.drop('Usage_kWh', axis=1).values\n",
    "y = df['Usage_kWh'].values.reshape(-1, 1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-22T14:53:21.443302600Z",
     "start_time": "2024-05-22T14:53:21.419621800Z"
    }
   },
   "id": "13a2b79306e7e288",
   "execution_count": 14
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "scaler_x = StandardScaler()\n",
    "scaler_y = StandardScaler()\n",
    "x_scaled = scaler_x.fit_transform(x)\n",
    "y_scaled = scaler_y.fit_transform(y)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-22T14:53:21.458638Z",
     "start_time": "2024-05-22T14:53:21.429465700Z"
    }
   },
   "id": "76fca719d15abce1",
   "execution_count": 15
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x_scaled, y_scaled, test_size=0.2, shuffle=False, random_state=42)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-22T14:53:21.459637900Z",
     "start_time": "2024-05-22T14:53:21.450302900Z"
    }
   },
   "id": "a64c57644694d86b",
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "gru = GRU(x_train.shape[1], 10, 1)\n",
    "gru.fit(x_train, y_train, epochs=100, learning_rate=0.001, batch_size=16)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-22T15:06:12.157138900Z",
     "start_time": "2024-05-22T14:53:21.460637200Z"
    }
   },
   "id": "80d74ae27481ff1b",
   "execution_count": 17
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def test_model(gru, x_test, y_test):\n",
    "    predictions = [gru.predict(x.reshape(1, -1)) for x in x_test]\n",
    "    predictions = np.array(predictions).reshape(-1, 1)\n",
    "\n",
    "    y_test_inverse = scaler_y.inverse_transform(y_test)\n",
    "    predictions_inverse = scaler_y.inverse_transform(predictions)\n",
    "    print(\"R2 Score:\\t\", r2_score(y_test_inverse, predictions_inverse))\n",
    "    print(\"RMSE:\\t\\t\", root_mean_squared_error(y_test_inverse, predictions_inverse))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-22T15:06:12.171140Z",
     "start_time": "2024-05-22T15:06:12.165140700Z"
    }
   },
   "id": "9094b4119f958724",
   "execution_count": 18
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 Score:\t 0.9082095402467093\n",
      "RMSE:\t\t 9.504735175985514\n"
     ]
    }
   ],
   "source": [
    "test_model(gru, x_test, y_test)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-22T15:06:12.689591500Z",
     "start_time": "2024-05-22T15:06:12.177142800Z"
    }
   },
   "id": "4cc7f5ea841d0d83",
   "execution_count": 19
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
